\documentclass{article}

% if you need to pass options to natbib, use, e.g.: \PassOptionsToPackage{numbers, compress}{natbib} before loading
%     neurips_2020

% ready for submission \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the [preprint] option:
% \usepackage[preprint]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.: \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
     \usepackage[preprint]{neurips_2020}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{listings}
\usepackage{graphicx}
\usepackage{subfigure}

\title{Semantic segmentation using full convolutional network}

% The \author macro works with any number of authors. There are two commands used to separate the names and addresses of
% multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the lines. Using \AND forces a line break at
% that point. So, if LaTeX puts 3 of 4 authors names on the first line, and the last on the second line, try using \AND
% instead of \And before the third author name.

\author{%
  Fangzhou Ai\\
  Department of Electrical and Computer Engineering\\
  University of California, San Diego\\
  La Jolla, CA 92093 \\
  \texttt{faai@eng.ucsd.edu} \\
  % examples of more authors
   \And Yue Qiao \\
   Department of Electrical and Computer Engineering \\
   University of California, San Diego\\
   La Jolla, CA 92093 \\
   \texttt{yuq021@eng.ucsd.edu}\\
   \And Zunming Zhang \\
   Department of Electrical and Computer Engineering \\
   University of California, San Diego\\
   La Jolla, CA 92093 \\
   \texttt{zuz008@eng.ucsd.edu}\\
}

\begin{document}

\maketitle

\begin{abstract}
    TBA
\end{abstract}

%--------------------------------------------

\section{Introduction}

%--------------------------------------------

\section{Related Work}

%--------------------------------------------

\section{Methods}

\subsection{Baseline}

\subsection{Experimentation}

%--------------------------------------------

\section{Results}

\subsection{Baseline model}

\subsection{Improved baseline model}

\subsection{Custom model}
Inspired by this \href{https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf}{paper}, we replace the encoder part in FCN model with the RRCNN layer instead, the RRCNN represent better abstraction ability, thus we would expect better IoU and precision. However the RRCNN is really memory-intensive, we have to crop the image to only 256 *256 size and delete 3 layers from original model's encoding part, which severly influence the performance of our model.
\subsection{Transfer learning}
In this part we employ the DEEPLABV3-RESNET101 model, which is a default pre-trained net work in PyTorch, from the \href{https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/}{official document} we know that this model is constructed by a Deeplabv3 model with a ResNet-101 backbone. The pre-trained model has been trained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset. We modifier the classifier part so that it could match the number of our feature, and we freeze the parameters of the pretrained part to accelerate the whole procedure.
\subsection{U-Net}
Folowing the routine demostrated in the \href{https://arxiv.org/pdf/1505.04597.pdf}{U-net paper}, we build the U-net by our self. The obvious difference is the U-net convolution block contains 2 convolution of the same size, while the FCN model only contains 1 convolution operation. We notice that the U-net model is also memory intensive while the datahub only give us a GTX 1080 ti with  11GB memory, hence there's a trade-off of between batch size, image size and model's completeness. We decide to crop the image and shrink the batch size to run the whole model, though this might not be the best solution, but this could give us a flavor of how the complete network looks like.

%--------------------------------------------

\section{Discussion}

%--------------------------------------------

\section{Individual contributions to the project}
\label{Sec:ICP}

\paragraph{Fangzhou Ai}
Custom model, Transfer learning and U-Net model.

\paragraph{Yue Qiao}

Evaluation metrics, Dataset loading and Baseline Model.

\paragraph{Zunming Zhang}

\end{document}